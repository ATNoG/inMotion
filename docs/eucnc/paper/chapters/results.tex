\section{Results and Discussion}\label{sec:results}

This section presents the experimental results from evaluating 38 machine learning classifiers on the \ac{RSSI}-based passenger movement dataset and analyses their implications across three experimental scenarios.

\subsection{Comparative Analysis Across Scenarios}

\autoref{tab:scenario_comparison} presents the performance comparison of top classifiers across the three experimental scenarios, revealing the substantial impact of data collection conditions on classification performance.

\begin{table}[!ht]
    \centering
    \caption{Performance Comparison Across Experimental Scenarios (\ac{MCC})}
    \label{tab:scenario_comparison}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{lccc}
            \toprule
            \textbf{Classifier}     & \textbf{Combined}          & \textbf{Isolated-Only}     & \textbf{Noisy-Only}        \\
            \midrule
            KNN (k=5)               & 0.692 $\pm$ 0.029          & \textbf{0.907 $\pm$ 0.061} & 0.704 $\pm$ 0.025          \\
            KNN (k=3)               & 0.690 $\pm$ 0.046          & 0.882 $\pm$ 0.068          & 0.702 $\pm$ 0.043          \\
            LinearSVC               & 0.726 $\pm$ 0.039          & 0.867 $\pm$ 0.060          & 0.716 $\pm$ 0.031          \\
            LogisticRegression (L2) & 0.743 $\pm$ 0.044          & 0.866 $\pm$ 0.028          & 0.731 $\pm$ 0.009          \\
            SVC (Linear)            & 0.750 $\pm$ 0.023          & 0.850 $\pm$ 0.088          & 0.731 $\pm$ 0.037          \\
            StackingEnsemble        & 0.749 $\pm$ 0.020          & 0.851 $\pm$ 0.122          & 0.768 $\pm$ 0.023          \\
            ExtraTrees              & 0.737 $\pm$ 0.013          & 0.836 $\pm$ 0.041          & 0.755 $\pm$ 0.021          \\
            GaussianProcess         & \textbf{0.756 $\pm$ 0.033} & 0.414 $\pm$ 0.052          & 0.755 $\pm$ 0.028          \\
            SVC (RBF)               & 0.755 $\pm$ 0.021          & 0.825 $\pm$ 0.101          & 0.754 $\pm$ 0.016          \\
            CatBoost                & 0.746 $\pm$ 0.017          & 0.782 $\pm$ 0.063          & \textbf{0.770 $\pm$ 0.013} \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

The isolated-only scenario yielded markedly superior performance, with \ac{KNN} (k=5) reaching an \ac{MCC} of 0.907---a 31\% relative improvement over the combined dataset. This increase stems from the absence of inter-device signal interference, producing cleaner \ac{RSSI} patterns with more distinct class separations. Simpler classifiers such as \ac{KNN}, which rely on local neighbourhood structure, benefit disproportionately from this increased separability.

Conversely, the \ac{GP} classifier suffered notable degradation in the isolated scenario (\ac{MCC}: 0.414) despite attaining the highest \ac{MCC} (0.756) on the combined dataset. This paradox is explained by the limited sample size ($n = 160$), which proves insufficient for reliable kernel hyperparameter estimation. On the combined dataset, the \ac{GP}'s probabilistic framework and \ac{RBF} kernel flexibility enable effective modelling of non-linear decision boundaries without extensive manual tuning.

The noisy-only scenario, representing the most realistic operational conditions, showed performance on par with the combined dataset, with CatBoost attaining the highest \ac{MCC} (0.770). This consistency indicates that the combined dataset's performance is largely driven by the noisy samples, which constitute 88\% of the total data. Gradient boosting methods demonstrated particular robustness to signal interference.

\subsection{Per-Class and Error Analysis}

\autoref{tab:class_performance} presents the per-class metrics for the best classifier in each scenario, averaged across three random seeds.

\begin{table}[!ht]
    \centering
    \caption{Per-Class Performance Metrics Across Scenarios (mean over three seeds)}
    \label{tab:class_performance}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{clcccc}
            \toprule
            \textbf{Scenario} & \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{MCC} \\
            \midrule
            \multirow{5}{*}{\shortstack[c]{Combined\\(\ac{GP})}}
            & AA (Inside)           & 0.784 & 0.726 & 0.754 & 0.676 \\
            & BB (Stop)             & 0.871 & 0.892 & 0.882 & 0.841 \\
            & BA (Boarding)         & 0.834 & 0.765 & 0.798 & 0.736 \\
            & AB (Alighting)        & 0.779 & 0.882 & 0.827 & 0.768 \\
            \cmidrule{2-6}
            & \textbf{Weighted Avg} & \textbf{0.817} & \textbf{0.816} & \textbf{0.815} & \textbf{0.756} \\
            \midrule
            \multirow{5}{*}{\shortstack[c]{Isolated\\\ac{KNN} ($k\!=\!5$)}}
            & AA (Inside)           & 0.896 & 0.875 & 0.866 & 0.842 \\
            & BB (Stop)             & 0.933 & 1.000 & 0.963 & 0.952 \\
            & BA (Boarding)         & 0.963 & 0.875 & 0.910 & 0.891 \\
            & AB (Alighting)        & 0.958 & 0.958 & 0.958 & 0.944 \\
            \cmidrule{2-6}
            & \textbf{Weighted Avg} & \textbf{0.938} & \textbf{0.927} & \textbf{0.924} & \textbf{0.907} \\
            \midrule
            \multirow{5}{*}{\shortstack[c]{Noisy\\(CatBoost)}}
            & AA (Inside)           & 0.784 & 0.800 & 0.791 & 0.721 \\
            & BB (Stop)             & 0.891 & 0.844 & 0.866 & 0.824 \\
            & BA (Boarding)         & 0.877 & 0.778 & 0.822 & 0.772 \\
            & AB (Alighting)        & 0.778 & 0.883 & 0.826 & 0.767 \\
            \cmidrule{2-6}
            & \textbf{Weighted Avg} & \textbf{0.833} & \textbf{0.826} & \textbf{0.826} & \textbf{0.770} \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

In the isolated scenario, all four classes exceed an F1-score of~0.86, with BB reaching~0.963 at perfect recall (1.000). The absence of inter-device interference produces cleaner \ac{RSSI} patterns, resulting in per-class F1-scores 10--15\% higher than in the combined and noisy scenarios.

Across all three scenarios, BB (bus stop) is the most accurately classified class, due to the consistent low \ac{RSSI} values caused by the physical barrier separating Zone~B from the access point. AB (alighting) maintains high recall (0.882--0.958) but comparatively lower precision, as the declining \ac{RSSI} pattern during exit partially overlaps with the static low-\ac{RSSI} signature of~BB.

AA (inside vehicle) presents the lowest recall in the combined scenario (0.726), primarily from misclassification as~BA. Both classes occupy Zone~A near the access point, producing similar high-\ac{RSSI} magnitudes. Although their temporal dynamics differ---stable values for AA versus an increasing trend for BA---this distinction is subtle within the 10-second observation window. This confusion is reduced in the isolated scenario (AA recall: 0.875), where the absence of interference makes temporal patterns more separable.

BA (boarding) exhibits the most scenario-dependent recall, ranging from 0.765 (combined) to 0.875 (isolated). In multi-device conditions, co-channel interference partially obscures the characteristic increasing \ac{RSSI} profile associated with an approaching passenger.

\subsection{Confusion Matrix Analysis}

\autoref{fig:confusion_matrix} presents the normalized confusion matrix for the \ac{GP} classifier.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.85\linewidth]{images/confusion_matrix_GaussianProcess.pdf}
    \caption{Confusion matrix for the \ac{GP} classifier, demonstrating strong diagonal dominance with minimal inter-class confusion.}
    \label{fig:confusion_matrix}
\end{figure}

The confusion matrix confirms that classification errors concentrate between spatially adjacent classes. The AA--BA confusion reflects \ac{RSSI} magnitude similarity when devices are near the access point, while the AB--BB confusion arises from both classes sharing lower \ac{RSSI} values characteristic of the exterior zone. These patterns suggest that additional features or longer observation windows could improve discrimination between static and transitional states.

\subsection{Model Stability}

\autoref{fig:accuracy_variability} illustrates the \ac{MCC} variability for top classifiers across the three random seeds.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{images/mcc_variability.pdf}
    \caption{\ac{MCC} variability for top classifiers, in combined dataset, demonstrating consistent ranking stability.}
    \label{fig:accuracy_variability}
\end{figure}

Top-performing classifiers maintain consistent relative rankings across seeds. Kernel-based methods (\ac{GP}, SVC) and ensemble approaches (Stacking, CatBoost) displayed the lowest variability, a desirable property for deployment scenarios where model retraining may occur with different data partitions.

\subsection{Feature Importance}

\autoref{fig:feature_importance} illustrates the mean feature importance across interpretable classifiers.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{images/mean_feature_importance.pdf}
    \caption{Mean feature importance across classifiers, with standard deviation, to the $[0, 1]$ range using min-max normalization}
    \label{fig:feature_importance}
\end{figure}

Initial \ac{RSSI} measurements (features 1--3) contribute most significantly to classification decisions, capturing the starting position and enabling immediate distinction between static and transitional states. Feature~1 exhibits the highest mean importance (normalized score: 0.99) with universal agreement among classifiers (standard deviation: 0.009). The elevated importance of feature~6 (mid-trajectory) indicates that classifiers also rely on signal evolution to confirm movement direction, validating the use of sequential \ac{RSSI} measurements over aggregate statistics.

\subsection{Hyperparameter Configuration}

While extensive hyperparameter optimization was performed for nine classifier families using Optuna, the \ac{GP} classifier employed default configurations with an \ac{RBF} kernel.

Details regarding the hyperparameter search spaces and the optimal configurations for all optimized classifiers are provided as supplementary material on GitHub \cite{githubrepo}.
The \ac{GP} configuration is presented in \autoref{tab:hyperparams}.

\begin{table}[!ht]
    \centering
    \caption{\ac{GP} Hyperparameters}
    \label{tab:hyperparams}
    \begin{tabularx}{\linewidth}{XX}

        \toprule
        \textbf{Parameter}   & \textbf{Value}               \\
        \midrule
        Kernel               & $1.0 \times \text{RBF}(1.0)$ \\
        Kernel Length Scale  & Optimized during fitting     \\
        Optimizer            & L-BFGS-B                     \\
        Max Iterations       & 100                          \\
        Multi-class Strategy & One-vs-Rest                  \\
        \bottomrule
    \end{tabularx}
\end{table}

The \ac{RBF} kernel automatically learns optimal length scale parameters during training, adapting to the intrinsic dimensionality of \ac{RSSI} sequences. Notably, the \ac{GP} achieved top performance without requiring the extensive hyperparameter search applied to other classifiers, suggesting that its probabilistic formulation is well-suited to the \ac{RSSI} feature space.

\subsection{Deployment Considerations}

The experimental results inform practical classifier selection. For high-interference environments with multiple simultaneous devices, gradient boosting methods (CatBoost, XGBoost) and ensemble approaches offer the best balance of accuracy and robustness. In controlled settings with minimal device density, simpler classifiers such as \ac{KNN} achieve superior performance with reduced computational overhead. For general deployment across varying conditions, SVC with \ac{RBF} kernel provides consistent performance with acceptable variance.

The notable performance improvement in isolated conditions (\ac{MCC} up to 0.907) indicates that signal interference is the chief limiting factor. Deployment strategies that mitigate interference, like dedicated frequency channels or directional antennas, could markedly enhance performance. Nevertheless, the results under noisy conditions (\ac{MCC} $>$ 0.77) confirm that \ac{RSSI}-based movement classification remains viable as a complementary passenger counting technology even in challenging environments.

\subsection{Limitations}

Several limitations warrant discussion. The controlled experimental environment, while designed to simulate public transport conditions, may not capture all sources of variability present in operational settings, such as passenger density fluctuations, vehicle movement, and diverse access point placements. The 10-second observation window, while suitable for typical boarding and alighting actions, may be insufficient for slower movements; adaptive window lengths could improve accuracy. The limited isolated dataset size ($n = 160$) further constrains reliability estimates for complex classifiers in that scenario.

Regarding energy consumption, the proposed approach imposes minimal overhead on passenger devices, as it leverages existing Wi-Fi associations without requiring additional active scanning. The access point performs passive \ac{RSSI} sampling, introducing no extra power drain on user devices. However, maintaining continuous Wi-Fi connectivity may affect battery life on devices with aggressive power-saving policies. On the infrastructure side, the access point's processing and energy overhead, while generally modest, may increase with higher device densities and more computationally demanding classification models, necessitating efficient implementation for real-time inference. Furthermore, certain router operating systems may enter power-saving modes that could disrupt continuous \ac{RSSI} monitoring; careful firmware configuration is therefore required to ensure uninterrupted data collection. A quantitative characterization of energy impact, on both client devices and access point hardware, across different deployment scales remains an avenue for future investigation.

Modern mobile operating systems employ \ac{MAC} address randomization during Wi-Fi probe requests, which can complicate device tracking in passive sensing scenarios. Our approach mitigates this challenge by relying on established Wi-Fi associations rather than passive scanning: once a device associates with the access point, it maintains a consistent \ac{MAC} address throughout the session, and the 10-second observation window operates well within a single association period, ensuring stable device identification. Nevertheless, devices that do not actively connect to the access point (or that cycle their \ac{MAC} address between association events) remain untrackable, imposing a practical ceiling on detection coverage. Variations in device hardware and operating system behaviour may further affect \ac{RSSI} reporting consistency in practice.
