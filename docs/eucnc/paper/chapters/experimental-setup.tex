\section{Experimental Setup}\label{sec:experimental-setup}

This section describes the physical data collection environment and the machine learning experimental framework employed for passenger movement classification.

\subsection{Physical Data Collection Setup}

Controlled experiments were conducted in an indoor environment emulating public transport interactions, enabling reproducible data collection under both isolated and noisy conditions.

\subsubsection{Environmental Configuration}

The environment was divided into two zones (\autoref{fig:experimental_setup}). Zone~A (Vehicle Interior) consisted of a closed room simulating a bus interior, with a WiFi access point positioned adjacent to the doorway. Zone~B (Bus Stop) was the corridor outside, representing the boarding area. The wall and door between zones introduce signal attenuation, generating distinctive RSSI patterns during transitions.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/experimental_setup.png}
    \caption{Experimental environment simulating a public transport scenario.}
    \label{fig:experimental_setup}
\end{figure}

\subsubsection{Data Acquisition}

Data was collected using a Python script interfacing with the AP via Ethernet. Each trial comprised a \textbf{10-second window} with \textbf{10 RSSI samples at 1~Hz}. Devices maintained periodic low-overhead traffic (ICMP) to ensure consistent RSSI reporting. Four mobile devices from three manufacturers were used to introduce hardware variability.

Four movement classes were defined: \textbf{A$\rightarrow$A} (remaining inside), \textbf{B$\rightarrow$B} (remaining at stop), \textbf{A$\rightarrow$B} (alighting), and \textbf{B$\rightarrow$A} (boarding). Collection occurred under two scenarios: \textit{Isolated} (single device, 20 repetitions per class per device) and \textit{Noisy} (four devices simultaneously performing paired movements).

\subsubsection{Preprocessing and Dataset Structure}

Raw data was transformed through: (1)~\textit{Temporal Aggregation}â€”10 RSSI measurements per trial aggregated into feature vector $\mathbf{R} = [r_1, \ldots, r_{10}]$; (2)~\textit{Device Isolation} using MAC addresses; (3)~\textit{Labeling} with movement class and noise indicator; (4)~\textit{Feature Filtering} to retain only RSSI values. The resulting CSV dataset contains approximately 1,360 samples, each representing a 10-second trajectory with movement class label, enabling analysis of both absolute signal strength and temporal evolution.

\subsection{Machine Learning Experimental Framework}

This subsection details the classifier selection rationale, evaluation methodology, and performance metrics employed in our experimental protocol.

\subsubsection{Classifier Selection and Justification}

We evaluated 38 classification algorithms spanning multiple paradigms to ensure comprehensive benchmarking. The classifier families were selected based on their established effectiveness in RSSI-based classification tasks~\cite{singh2021rssisurvey, zholamanov2025rssi}:

\textbf{Support Vector Machines (SVM):} SVMs with RBF and linear kernels were included due to their demonstrated superiority in WiFi fingerprinting tasks. Prior studies on indoor localization using RSSI have shown SVMs achieving accuracies exceeding 90\% for location classification~\cite{agualimpia2024rssi, jain2021lowcost}. The RBF kernel effectively captures non-linear relationships in signal strength patterns.

\textbf{Ensemble Methods:} Random Forest and Extra Trees were selected for their robustness to noise and ability to model complex decision boundaries without extensive hyperparameter tuning~\cite{singh2021rssisurvey}. Gradient boosting variants (XGBoost, LightGBM, CatBoost) were included based on their state-of-the-art performance in tabular classification tasks, with CatBoost demonstrating particular effectiveness for categorical features~\cite{fabre2025machine}.

\textbf{Gaussian Process Classifier:} GPs provide probabilistic predictions with uncertainty quantification, particularly valuable for RSSI data where signal variability is inherent. The RBF kernel enables automatic adaptation to the intrinsic dimensionality of temporal RSSI sequences.

\textbf{Neural Networks:} Multi-layer perceptrons (MLPs) with varying architectures (small, medium, large) were evaluated to assess whether deeper representations improve classification over traditional methods for this feature space dimensionality.

\textbf{Stacking and Voting Ensembles:} Meta-learning approaches combining heterogeneous base learners were included to leverage complementary classifier strengths, a strategy shown to improve robustness in transportation sensing applications~\cite{wiboonsiriruk2023efficient}.

\subsubsection{Data Partitioning Strategy}

The dataset was partitioned using \textbf{stratified sampling} with an 80\%/20\% train-test split. Stratified sampling ensures that class distributions are preserved in both partitions, which is critical for multi-class classification problems where class imbalance could otherwise bias model evaluation. This approach maintains the original proportion of each movement class (AA, BB, AB, BA) in both training and testing sets.

\subsubsection{Cross-Validation Protocol}

Model training employed \textbf{5-fold stratified cross-validation}, a methodology widely recommended for robust classifier evaluation. Stratified K-fold cross-validation maintains class ratios across all folds, ensuring that minority classes receive adequate representation during training and validation. This technique reduces variance in performance estimates compared to simple hold-out validation.

To assess result stability, experiments were repeated with three random seeds (3, 5, and 42), and metrics were aggregated across runs. This multi-seed evaluation quantifies classifier sensitivity to random initialization and data shuffling.

\subsubsection{Performance Metrics}

Four complementary metrics were employed to provide comprehensive performance characterization:

\textbf{Accuracy:} The proportion of correctly classified samples. While intuitive, accuracy can be misleading for imbalanced datasets.

\textbf{Weighted F1-Score:} The harmonic mean of precision and recall, weighted by class support. This metric balances false positives and false negatives while accounting for class distribution.

\textbf{Balanced Accuracy:} The arithmetic mean of per-class recall values, ensuring equal contribution from each class regardless of prevalence.

\textbf{Matthews Correlation Coefficient (MCC):} Selected as the primary evaluation criterion, as this metric offers a reliable and balanced evaluation of classification models, particularly in scenarios involving imbalanced datasets or when assessing performance across multiple classes~\cite{chicco2020mcc, chicco2023mcc}. MCC ranges from $-1$ to $+1$, producing high scores only when all confusion matrix categories achieve strong results.