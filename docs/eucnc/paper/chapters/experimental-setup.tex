\section{Experimental Setup}\label{sec:experimental-setup}

This section outlines the physical data collection environment and the machine learning experimental framework devised for passenger movement classification.

\subsection{Physical Data Collection Setup}

Controlled experiments were carried out in an indoor environment that emulates public transport interactions, allowing reproducible data collection under both isolated and noisy conditions.

\subsubsection{Environmental Configuration}

The environment was divided into two zones (\autoref{fig:experimental_setup}). Zone~A (Vehicle Interior) consisted of a closed room simulating a bus interior, with a Wi-Fi access point positioned adjacent to the doorway. Zone~B (Bus Stop) was the corridor outside, representing the boarding area. The wall and door between zones introduce signal attenuation, generating distinctive \ac{RSSI} patterns during transitions.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/experimental_setup.png}
    \caption{Experimental environment simulating a public transport scenario.}
    \label{fig:experimental_setup}
\end{figure}

\subsubsection{Data Acquisition}

Data was collected using a Python script interfacing with the Acess Point via Ethernet. Each trial comprised a \textbf{10-second window} with \textbf{10 \ac{RSSI} samples at 1~Hz}. Devices maintained periodic low-overhead traffic (ICMP) to ensure consistent \ac{RSSI} reporting. Four mobile devices from three manufacturers were used to introduce hardware variability.

Four movement classes were defined: \textbf{A$\rightarrow$A} (remaining inside), \textbf{B$\rightarrow$B} (remaining at stop), \textbf{A$\rightarrow$B} (alighting), and \textbf{B$\rightarrow$A} (boarding). Collection occurred under two scenarios: \textit{Isolated} (single device, 20 repetitions per class per device) and \textit{Noisy} (four devices simultaneously performing paired movements).

\subsubsection{Preprocessing and Dataset Structure}

Raw data underwent the following preprocessing steps: (1)~\textit{Temporal Aggregation}, where 10 \ac{RSSI} measurements per trial were aggregated into a feature vector $\mathbf{R} = [r_1, \ldots, r_{10}]$; (2)~\textit{Device Isolation} using \ac{MAC} addresses; (3)~\textit{Labeling} with movement class and noise indicator; and (4)~\textit{Feature Filtering} to retain only \ac{RSSI} values.

Prior to model training, \textit{Feature Scaling} was applied using standardization (z-score normalization), which transforms each feature to zero mean and unit variance. This step is essential for classifiers sensitive to feature magnitudes, such as \acp{SVM}, \ac{GP} classifiers, \acp{MLP}, and logistic regression, as these distance-based and gradient-based methods may otherwise suffer from degraded convergence speed and classification performance when operating on raw \ac{RSSI} value ranges.

The resulting dataset contains 1,356 samples, each representing a 10-second trajectory with a corresponding movement class label, enabling analysis of both absolute signal strength and temporal evolution.

\subsubsection{Experimental Scenarios}

To comprehensively evaluate the impact of data collection conditions on classification performance, three distinct experimental scenarios were defined:

\textbf{Combined Dataset:} The complete dataset containing all 1,356 samples from both isolated and noisy collection conditions. This scenario represents the most realistic deployment setting, where the classifier must generalize across varying environmental conditions.

\textbf{Isolated-Only Dataset:} A subset containing exclusively samples collected under isolated conditions (single device, $n = 160$). This scenario provides an upper-bound estimate of classification performance under ideal conditions with minimal signal interference.

\textbf{Noisy-Only Dataset:} A subset containing exclusively samples collected with simultaneous multi-device activity ($n = 1,196$). This scenario evaluates classifier robustness under challenging conditions that closely approximate real-world public transport environments.

Comparing across these scenarios allows for a quantitative assessment of how environmental noise affects classification accuracy and sheds light on the operational boundaries of \ac{RSSI}-based movement detection.

\subsection{Machine Learning Experimental Framework}

The following subsection details the classifier selection rationale, evaluation methodology, and performance metrics adopted in our experimental protocol.

\subsubsection{Classifier Selection and Justification}

A total of 38 classification algorithms spanning multiple paradigms were evaluated to ensure thorough benchmarking. The classifier families were chosen based on their established effectiveness in \ac{RSSI}-based classification tasks~\cite{singh2021rssisurvey, zholamanov2025rssi}:

\textbf{Support Vector Machines (SVM):} \acp{SVM} with \ac{RBF} and linear kernels were included due to their demonstrated superiority in Wi-Fi fingerprinting tasks. Prior studies on indoor localization using \ac{RSSI} have shown \acp{SVM} achieving accuracies exceeding 90\% for location classification~\cite{agualimpia2024rssi, jain2021lowcost}. The \ac{RBF} kernel effectively captures non-linear relationships in signal strength patterns.

\textbf{Ensemble Methods:} Random Forest and Extra Trees were selected for their robustness to noise and ability to model complex decision boundaries without extensive hyperparameter tuning~\cite{singh2021rssisurvey}. Gradient boosting variants (XGBoost, LightGBM, CatBoost) were included based on their state-of-the-art performance in tabular classification tasks, with CatBoost demonstrating particular effectiveness for categorical features~\cite{fabre2025machine}.

\textbf{Gaussian Process Classifier:} \acp{GP} provide probabilistic predictions with uncertainty quantification, particularly valuable for \ac{RSSI} data where signal variability is inherent. The \ac{RBF} kernel enables automatic adaptation to the intrinsic dimensionality of temporal \ac{RSSI} sequences.

\textbf{Neural Networks:} \acp{MLP} with varying architectures (small, medium, large) were evaluated to assess whether deeper representations improve classification over traditional methods for this feature space dimensionality.

\textbf{Stacking and Voting Ensembles:} Meta-learning approaches combining heterogeneous base learners were included to leverage complementary classifier strengths, a strategy shown to improve robustness in transportation sensing applications~\cite{wiboonsiriruk2023efficient}.

\subsubsection{Data Partitioning Strategy}

The dataset was partitioned using \textbf{stratified sampling} with an 80\%/20\% train-test split. Stratified sampling ensures that class distributions are preserved in both partitions, which is critical for multi-class classification problems where class imbalance could otherwise bias model evaluation. This approach maintains the original proportion of each movement class (AA, BB, AB, BA) in both training and testing sets.

\subsubsection{Cross-Validation Protocol}

Model training employed \textbf{5-fold stratified cross-validation}, a methodology widely recommended for robust classifier evaluation. Stratified K-fold cross-validation maintains class ratios across all folds, ensuring that minority classes receive adequate representation during training and validation. This technique reduces variance in performance estimates compared to simple hold-out validation.

To assess result stability, experiments were repeated with three random seeds (3, 5, and 42), and metrics were aggregated across runs. This multi-seed evaluation quantifies classifier sensitivity to random initialization and data shuffling.

\subsubsection{Hyperparameter Optimization}

To ensure fair comparison and optimal performance across classifier families, systematic hyperparameter optimization was conducted using Optuna~\cite{optuna2019}, a state-of-the-art Bayesian optimization framework. Optuna employs the Tree-structured Parzen Estimator (TPE) algorithm to efficiently explore high-dimensional hyperparameter spaces, focusing search efforts on promising regions.

For each tunable classifier, extensive hyperparameter searches were performed with budgets ranging from 50 to over 1,300 trials depending on model complexity. The optimization objective was accuracy during 5-fold stratified cross-validation on the training set. This approach yields classifier configurations specifically adapted to the \ac{RSSI} feature space characteristics.

The hyperparameter search spaces were defined based on recommended ranges from the literature and practical considerations. Ensemble methods (Random Forest, Extra Trees, Gradient Boosting variants) were tuned over tree depth, number of estimators, and regularization parameters. \acp{SVM} were optimized for the regularization parameter $C$ and kernel coefficients. Neural network configurations explored layer architectures, learning rates, and regularization strengths. The complete hyperparameter search spaces and optimal configurations for each classifier are documented in the Appendix.

\subsubsection{Performance Metrics}

Four complementary metrics were employed to provide comprehensive performance characterization:

\textbf{Accuracy:} The proportion of correctly classified samples. While intuitive, accuracy can be misleading for imbalanced datasets.

\textbf{Weighted F1-Score:} The harmonic mean of precision and recall, weighted by class support. This metric balances false positives and false negatives while accounting for class distribution.

\textbf{Balanced Accuracy:} The arithmetic mean of per-class recall values, ensuring equal contribution from each class regardless of prevalence.

\textbf{Matthews Correlation Coefficient (MCC):} Selected as the primary evaluation criterion, as this metric offers a reliable and balanced evaluation of classification models, particularly in scenarios involving imbalanced datasets or when assessing performance across multiple classes~\cite{chicco2020mcc, chicco2023mcc}. \ac{MCC} ranges from $-1$ to $+1$, producing high scores only when all confusion matrix categories achieve strong results.