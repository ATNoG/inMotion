======================================================================
CLASSIFICATION RESULTS REPORT
======================================================================

Total classifiers evaluated: 39
Cross-validation folds: 5
Test set size: 20%

----------------------------------------------------------------------
TOP 10 CLASSIFIERS BY ACCURACY
----------------------------------------------------------------------
1. LogisticRegression_L2: Acc=0.8382, F1=0.8366, CV=0.7832±0.0255
2. LogisticRegression_ElasticNet: Acc=0.8382, F1=0.8365, CV=0.7823±0.0259
3. LogisticRegression_L1: Acc=0.8382, F1=0.8365, CV=0.7795±0.0275
4. SVC_Linear: Acc=0.8272, F1=0.8259, CV=0.7915±0.0350
5. SVC_RBF: Acc=0.8272, F1=0.8248, CV=0.7924±0.0392
6. MLP_Large: Acc=0.8235, F1=0.8211, CV=0.7611±0.0390
7. StackingEnsemble: Acc=0.8235, F1=0.8214, CV=0.8007±0.0190
8. GaussianProcess: Acc=0.8199, F1=0.8173, CV=0.7888±0.0334
9. MLP_L2: Acc=0.8199, F1=0.8186, CV=0.7583±0.0096
10. MLP_Medium: Acc=0.8199, F1=0.8186, CV=0.7583±0.0096

----------------------------------------------------------------------
BEST CLASSIFIER: LogisticRegression_L2
----------------------------------------------------------------------

Accuracy: 0.8382
Balanced Accuracy: 0.8382
Precision (weighted): 0.8368
Recall (weighted): 0.8382
F1 Score (weighted): 0.8366
CV Score: 0.7832 ± 0.0255
Training Time: 0.05s

Classification Report:
  AA: precision=0.803, recall=0.721, f1=0.760
  BB: precision=0.886, recall=0.912, f1=0.899
  BA: precision=0.809, recall=0.809, f1=0.809
  AB: precision=0.849, recall=0.912, f1=0.879
  macro avg: precision=0.837, recall=0.838, f1=0.837
  weighted avg: precision=0.837, recall=0.838, f1=0.837

----------------------------------------------------------------------
FEATURE IMPORTANCE (AVERAGED ACROSS CLASSIFIERS)
----------------------------------------------------------------------
  1: 106.6038
  2: 81.8378
  10: 75.8571
  6: 63.7382
  9: 63.2610
  3: 61.3269
  5: 58.7699
  8: 58.4713
  7: 53.5204
  4: 52.9133

======================================================================